{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d28fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnlibrary.configs.hvac_mode_classifier as cfg\n",
    "from nnlibrary.engines import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67fe721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HDF5 Dataset Info for train.h5:\n",
      "  Input chunks: (100, 48, 16) (chunk = 0.29 MB)\n",
      "  Output chunks: (100, 3) (chunk = 0.00 MB)\n",
      "\n",
      "  Loading entire dataset into memory from /home/ahojrup/GitLab/mpc_ahu_neural_network/data/14days_2025-09-09_2025-09-23/dataset/train.h5...\n",
      "    Expected memory usage:\n",
      "      Inputs:  (16694, 48, 16) × float32 = 0.048 GB\n",
      "      Outputs: (16694, 3) × float32 = 0.000 GB\n",
      "      Total:   0.048 GB\n",
      "\n",
      "  Actual memory allocated: 0.051 GB\n",
      "  Loaded 16,694 samples into memory\n",
      "  Effective compression ratio: 0.95x\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandreas-hovaldt\u001b[0m (\u001b[33mbe-ics-acs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ahojrup/GitLab/mpc_ahu_neural_network/exp/14days_2025-09-09_2025-09-23/HVACModeMLP/wandb/run-20250926_154512-ouvg9zzb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/be-ics-acs/nnlibrary/runs/ouvg9zzb' target=\"_blank\">golden-flower-27</a></strong> to <a href='https://wandb.ai/be-ics-acs/nnlibrary' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/be-ics-acs/nnlibrary' target=\"_blank\">https://wandb.ai/be-ics-acs/nnlibrary</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/be-ics-acs/nnlibrary/runs/ouvg9zzb' target=\"_blank\">https://wandb.ai/be-ics-acs/nnlibrary/runs/ouvg9zzb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea385692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected `device_type` of type `str`, got: `<class 'torch.device'>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitLab/mpc_ahu_neural_network/nnlibrary/engines/train.py:73\u001b[39m, in \u001b[36mTrainerBase.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info[\u001b[33m\"\u001b[39m\u001b[33mepoch_iter\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m.info[\u001b[33m\"\u001b[39m\u001b[33miter_data\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.trainloader):\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mself\u001b[39m.before_step()\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mself\u001b[39m.after_step()\n\u001b[32m     76\u001b[39m \u001b[38;5;28mself\u001b[39m.after_epoch()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitLab/mpc_ahu_neural_network/nnlibrary/engines/train.py:168\u001b[39m, in \u001b[36mTrainer.run_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    165\u001b[39m     y_batch = y_batch.to(device=\u001b[38;5;28mself\u001b[39m.device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mamp_enable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mamp_dtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m    171\u001b[39m     y_pred: torch.Tensor = \u001b[38;5;28mself\u001b[39m.model(X_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/amp/autocast_mode.py:226\u001b[39m, in \u001b[36mautocast.__init__\u001b[39m\u001b[34m(self, device_type, dtype, enabled, cache_enabled)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    220\u001b[39m     device_type: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    223\u001b[39m     cache_enabled: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    224\u001b[39m ):\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device_type, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    227\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected `device_type` of type `str`, got: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(device_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    228\u001b[39m         )\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    230\u001b[39m         dtype = torch.get_autocast_dtype(device_type)\n",
      "\u001b[31mValueError\u001b[39m: Expected `device_type` of type `str`, got: `<class 'torch.device'>`"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df7c886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4045, -1.4380, -6.0174, -3.8171, -5.6814],\n",
      "         [-0.4045, -1.4380, -6.0174, -3.8171, -5.6814]]]) \n",
      "\n",
      " torch.Size([1, 2, 5]) \n",
      "\n",
      "\n",
      "tensor([[[-0.4045, -1.4380, -6.0174, -3.8171, -5.6814],\n",
      "         [-0.4045, -1.4380, -6.0174, -3.8171, -5.6814]]]) \n",
      "\n",
      " torch.Size([1, 2, 5]) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "import sys; sys.path.append('..')\n",
    "from nnlibrary.utils.operations import Standardize\n",
    "        \n",
    "\n",
    "\n",
    "means: np.ndarray = np.load(\"/home/ahojrup/GitLab/mpc_ahu_neural_network/data/730days_2023-09-24_2025-09-23/dataset-regression/stats/target_mean.npy\")\n",
    "stds: np.ndarray = np.load(\"/home/ahojrup/GitLab/mpc_ahu_neural_network/data/730days_2023-09-24_2025-09-23/dataset-regression/stats/target_std.npy\")\n",
    "test_target = torch.as_tensor(data=[[5,5,5,5,5],[5,5,5,5,5]], dtype=torch.float32).unsqueeze(dim=0)\n",
    "\n",
    "transform = v2.Compose([\n",
    "    Standardize(mean=means.astype(float).tolist(), std=stds.astype(float).tolist()),\n",
    "])\n",
    "\n",
    "transformed_target = transform(test_target)\n",
    "print(transformed_target, \"\\n\\n\", transformed_target.shape, \"\\n\\n\")\n",
    "\n",
    "transform = Standardize(mean=means.astype(float).tolist(), std=stds.astype(float).tolist())\n",
    "transformed_target = transform(test_target)\n",
    "print(transformed_target, \"\\n\\n\", transformed_target.shape, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc13d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 14]) torch.Size([5])\n",
      "Applied target_transform!\n",
      "torch.Size([32, 14]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('..')\n",
    "from nnlibrary.datasets import MpcDatasetHDF5\n",
    "from pathlib import Path\n",
    "from nnlibrary.utils.operations import Standardize\n",
    "import numpy as np\n",
    "\n",
    "dataset_dir = Path(\"/home/ahojrup/GitLab/mpc_ahu_neural_network/data/730days_2023-09-24_2025-09-23/dataset-regression-mode\")\n",
    "standardize_transform = Standardize(\n",
    "    mean=np.load(dataset_dir / \"stats\" / \"target_mean.npy\").astype(float).tolist(),\n",
    "    std=np.load(dataset_dir / \"stats\" / \"target_std.npy\").astype(float).tolist(),\n",
    ")\n",
    "\n",
    "dataset = MpcDatasetHDF5(\n",
    "    hdf5_file=dataset_dir / \"train.h5\",\n",
    "    task='regression',\n",
    "    target_transform=None,\n",
    ")\n",
    "x, y = dataset.__getitem__(index=0)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "dataset_standardized = MpcDatasetHDF5(\n",
    "    hdf5_file=dataset_dir / \"train.h5\",\n",
    "    task='regression',\n",
    "    target_transform=standardize_transform,\n",
    ")\n",
    "x_std, y_std = dataset_standardized.__getitem__(index=0)\n",
    "print(x_std.shape, y_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f80717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000, 77.2230, 15.0000, 14.3489, 14.3366]) tensor([-0.5630,  0.4159, -0.9124, -1.0703, -1.1158])\n",
      "torch.float32 torch.float32\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([-0.5630,  0.4159, -0.9124, -1.0703, -1.1158])\n"
     ]
    }
   ],
   "source": [
    "print(y, y_std)\n",
    "print(y.dtype, y_std.dtype)\n",
    "print(type(y), type(y_std))\n",
    "\n",
    "\n",
    "print(standardize_transform(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
